version: "3.8"

services:
  chat:
    image: ghcr.io/open-webui/open-webui:0.4.8
    ports:
      - 8080:8080
    environment:
      ENABLE_SIGNUP: "false" # change to false after admin created
      ENABLE_OLLAMA_API: "false"
      OPENAI_API_KEYS: ${OPENAI_API_KEY};${PIPELINES_API_KEY}
      OPENAI_API_BASE_URLS: ;http://pipelines:9099
      AUDIO_STT_ENGINE: openai
      AUDIO_TTS_ENGINE: openai
      ENABLE_IMAGE_GENERATION: "true"
      IMAGE_GENERATION_ENGINE: openai
      DEFAULT_MODELS: gpt-4o
    volumes:
      - "open-webui:/app/backend/data"
    deploy:
      replicas: 0
      restart_policy:
        condition: on-failure
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.chat.middlewares=allow-public@file"
        - "traefik.http.routers.chat.rule=Host(`chat.oliverlambson.com`) || HostRegexp(`^chat(\\..+)?$`)"
        - "traefik.http.routers.chat.entrypoints=websecure"
        - "traefik.http.routers.chat.tls.certresolver=letsencrypt"
        - "traefik.http.services.chat.loadbalancer.server.port=8080"
        - "traefik.http.routers.chat.tls.domains[0].main=chat.oliverlambson.com"
    networks:
      - public
      - private
  pipelines:
    image: ghcr.io/open-webui/pipelines:git-1367d95
    ports:
      - 9099:9099
    environment:
      PIPELINES_URLS: "https://github.com/open-webui/pipelines/blob/main/examples/pipelines/providers/anthropic_manifold_pipeline.py"
      PIPELINES_API_KEY: ${PIPELINES_API_KEY}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
    volumes:
      - "pipelines:/app/pipelines"
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
    networks:
      - private

volumes:
  open-webui:
  pipelines:

networks:
  public:
    external: true
  private:
    external: true
